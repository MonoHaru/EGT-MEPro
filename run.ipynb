{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from utils.ML import time_series_dataframe, make_dataframe\n",
    "from utils.DL import new_multistep_time_series, plot_and_loss2\n",
    "from utils.DL import train_tmp, evaluate2\n",
    "from utils.DL import TransAm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step - Fault Diagnositics using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load Dataset ######\n",
    "print(f'>>> Load Dataset!')\n",
    "\n",
    "df_ML = make_dataframe(path_temp_gps='./temp_add_gps/',\n",
    "                       window_size=120,\n",
    "                       stride=40)\n",
    "\n",
    "X = df_ML.iloc[:, :9].values\n",
    "y = df_ML['label'].values\n",
    "\n",
    "# Data Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "\n",
    "# Preprocessing\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "x_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'X_train Shape : {X_train_scaled.shape}')\n",
    "print(f'X_test Shape : {x_test_scaled.shape}')\n",
    "print(f'>>> Successfully load dataset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load Model ######\n",
    "print(f'>>> Load Model!')\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators=50, \n",
    "                             max_depth = 30, \n",
    "                             random_state = 42, \n",
    "                             min_samples_leaf=8, \n",
    "                             min_samples_split=8)\n",
    "\n",
    "print(f'>>> Successfully load model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Train & Test ######\n",
    "\n",
    "RFC.fit(X_train_scaled, y_train)\n",
    "RFC_predict = RFC.predict(x_test_scaled)\n",
    "RFC_acc = accuracy_score(y_test, RFC_predict)\n",
    "\n",
    "print(\"Random Forest Classifier Precition Accuracy : \", RFC_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Step - Time-Series Prediction using Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "input_window = 240\n",
    "output_window = 120\n",
    "epochs = 500\n",
    "# batch_size = 1024\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load Dataset #####\n",
    "print(f'>>> Load Dataset!')\n",
    "\n",
    "df_DL, _, _ = time_series_dataframe('./temp_add_gps/')\n",
    "\n",
    "df_DL_temp = df_DL['TEMP'].values\n",
    "df_DL_label = df_DL['label'].values\n",
    "\n",
    "# Preprocessing\n",
    "scaler_train = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "train_len = int(len(df_DL) * 0.8)\n",
    "\n",
    "train_data = df_DL_temp[:train_len]\n",
    "train_label = df_DL_label[:train_len]\n",
    "test_data = df_DL_temp[train_len:]\n",
    "test_label = df_DL_label[train_len:]\n",
    "\n",
    "train_data = scaler_train.fit_transform(train_data.reshape(-1,1)).reshape(-1)\n",
    "test_data = scaler_test.fit_transform(test_data.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "train_data, _ = new_multistep_time_series(train_data, train_label, input_window, output_window)\n",
    "test_data, test_label = new_multistep_time_series(test_data, test_label, input_window, output_window)\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "print(f'X_train Shape : {train_data.shape}')\n",
    "print(f'X_test Shape : {test_data.shape}')\n",
    "print(f'>>> Successfully load dataset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load Model ######\n",
    "print(f'>>> Load Model!')\n",
    "\n",
    "model = TransAm().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
    "\n",
    "print(f'>>> Successfully load model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Train & Test #####\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    train_tmp(model, train_data, batch_size, optimizer, criterion, input_window, output_window, epoch, scheduler)\n",
    "    \n",
    "    if (epoch % 20 == 0):\n",
    "        truth, test_result, result_to_ML, val_loss = plot_and_loss2(model, test_data, criterion,input_window, output_window, scaler_test)\n",
    "    else:\n",
    "        val_loss = evaluate2(model, test_data, criterion, output_window, input_window)\n",
    "    \n",
    "    print('-' * 90)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f} |'.format(epoch, (time.time() - start_time),\n",
    "                                        val_loss, math.exp(val_loss)))\n",
    "    print('-' * 90)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "\n",
    "PATH = \"./checkpoints/\"\n",
    "torch.save(model, PATH + 'prediction_model.pt')\n",
    "torch.save(model.state_dict(), PATH + 'prediction_model_state_dict.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Step - Fault Prognostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './checkpoints/'\n",
    "model = torch.load(PATH + 'prediction_model.pt', map_location=torch.device('cuda:0')) \n",
    "model.load_state_dict(torch.load(PATH + 'prediction_model_state_dict.pt', map_location=torch.device('cuda:0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'label' : []}\n",
    "\n",
    "def DF_to_DataFrame(data):\n",
    "    mean = np.round(np.mean(data), 3)\n",
    "    min = np.min(data)\n",
    "    max = np.max(data)\n",
    "    std = np.std(data)\n",
    "    median = data.median()\n",
    "    sk = data.skew()\n",
    "    kurt = data.kurt()\n",
    "    a, b = np.percentile(data, q = [25,75])\n",
    "    \n",
    "    return mean, min, max, std, median, sk, kurt, a, b\n",
    "\n",
    "test_input = test_data[:, 0, :]\n",
    "test_input = test_input.unsqueeze(1)\n",
    "test_input = test_input.transpose(0, 2)\n",
    "test_input.shape\n",
    "\n",
    "test_target = test_data[:, 1, :]\n",
    "test_target = test_target.unsqueeze(1)\n",
    "test_target = test_target.transpose(0, 2)\n",
    "test_target.shape\n",
    "\n",
    "def test_batch(data, index):\n",
    "    data = data[:, :, index].unsqueeze(2)\n",
    "    return data\n",
    "\n",
    "def test_input_batch(data, index):\n",
    "    data = data[:, :, index].unsqueeze(2)\n",
    "    return data\n",
    "\n",
    "def test_target_batch(data, index):\n",
    "    data = data[:, :, index].unsqueeze(2)\n",
    "    return data\n",
    "\n",
    "def r2_score(target, output):\n",
    "    avg = torch.mean(target)\n",
    "    ss_res = torch.sum((target - output) ** 2)\n",
    "    ss_tot = torch.sum((target - avg) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2\n",
    "\n",
    "\n",
    "def test_rmse_mae_r2(target, output):\n",
    "    rmse = np.sqrt(mean_squared_error(target, output))\n",
    "    mae = mean_absolute_error(target, output)\n",
    "    r2 = r2_score(torch.from_numpy(target), torch.from_numpy(output))\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = []\n",
    "mae_list = []\n",
    "r2_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_data))):\n",
    "        input, target = test_input_batch(test_input, i), test_target_batch(test_target, i)\n",
    "        output = model(input)\n",
    "\n",
    "        output = output[-120:].detach().cpu()\n",
    "        target = target[-120:].detach().cpu()\n",
    "\n",
    "        output = scaler_test.inverse_transform(output.reshape(-1,1)).reshape(-1)\n",
    "        target = scaler_test.inverse_transform(target.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "        rmse, mae, r2= test_rmse_mae_r2(target[-120:], output[-120:])\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "        output = list(output)\n",
    "        output = pd.DataFrame({'TEMP' : output})\n",
    "        A = output['TEMP']\n",
    "        mean, min, max, std, median, skew, kurt, a, b, = DF_to_DataFrame(A)\n",
    "        DataFrame['label'].append(test_label[i])\n",
    "        DataFrame['MEAN_TEMP'].append(mean)\n",
    "        DataFrame['MIN'].append(min)\n",
    "        DataFrame['MAX'].append(max)\n",
    "        DataFrame['STD'].append(std)\n",
    "        DataFrame['SKEW'].append(skew)\n",
    "        DataFrame['KURT'].append(kurt)\n",
    "        DataFrame['MEDIAN'].append(np.round(median,3))\n",
    "        DataFrame['25%'].append(np.round(a,3))\n",
    "        DataFrame['75%'].append(np.round(b,3))\n",
    "    \n",
    "print(f\"Average RMSE : {np.mean(rmse_list)}\")\n",
    "print(f\"Average MAE : {np.mean(mae_list)}\")\n",
    "print(f\"Average R2 : {np.mean(r2_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prognostics\n",
    "\n",
    "DF = pd.DataFrame(DataFrame)\n",
    "\n",
    "transformer_X = DF.iloc[:, :9].values\n",
    "transformer_y = DF['label'].values\n",
    "\n",
    "transformer_scaled = scaler.transform(transformer_X)\n",
    "transformer_predict = RFC.predict(transformer_scaled)\n",
    "transformer_ac = accuracy_score(transformer_predict, transformer_y)\n",
    "\n",
    "print(\"Random Forest Classifier Precition Accuracy : \", transformer_ac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
