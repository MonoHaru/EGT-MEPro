{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ML import time_series_dataframe_ML, make_dataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils.DL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_ts_ML, _, _ = time_series_dataframe_ML()\n",
    "window_size, stride = 120, 40\n",
    "\n",
    "# Load Dataset\n",
    "df_ML = make_dataframe(window_size, stride)\n",
    "X = df_ML.iloc[:, :9].values\n",
    "y = df_ML['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "\n",
    "# Scale Data\n",
    "scaler_ML = MinMaxScaler()\n",
    "X_train_scaled = scaler_ML.fit_transform(X_train)\n",
    "x_test_scaled = scaler_ML.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest\n",
    "RFC = RandomForestClassifier(n_estimators=50, max_depth = 30, random_state = 42, min_samples_leaf=8, min_samples_split=8)\n",
    "\n",
    "# Train Random Forest\n",
    "RFC.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "RFC_predict = RFC.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "RFC_ac = accuracy_score(y_test, RFC_predict)\n",
    "\n",
    "print(\"Random Forest Classifier Precition Accuracy : \", RFC_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter\n",
    "input_window = 240\n",
    "output_window = 120\n",
    "epochs = 500\n",
    "batch_size = 1024\n",
    "df_DL = time_series_dataframe_ML()\n",
    "\n",
    "# Split Train Test\n",
    "df_DL_temp = df_DL['TEMP'].values\n",
    "df_DL_label = df_DL['label'].values\n",
    "\n",
    "scaler_train = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "train_len = int(len(df_DL) * 0.8)\n",
    "\n",
    "train_data = df_DL_temp[:train_len]\n",
    "test_data = df_DL_temp[train_len:]\n",
    "train_label = df_DL_label[:train_len]\n",
    "test_label = df_DL_label[train_len:]\n",
    "\n",
    "train_data = scaler_train.fit_transform(train_data.reshape(-1,1)).reshape(-1)\n",
    "test_data = scaler_test.fit_transform(test_data.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "# Make Data to PyTorch Tensor\n",
    "train_data, _ = new_multistep_time_series(train_data, train_label, input_window, output_window)\n",
    "test_data, test_label = new_multistep_time_series(test_data, test_label, input_window, output_window)\n",
    "\n",
    "# Setting\n",
    "lr = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "model = TransAm().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    train_tmp(model, train_data,batch_size, optimizer, criterion, input_window, output_window, epoch, scheduler)\n",
    "    \n",
    "    if (epoch % 20 == 0):\n",
    "        truth, test_result, result_to_ML, val_loss = plot_and_loss2(model, test_data, criterion,input_window, output_window, scaler_test)\n",
    "    else:\n",
    "        val_loss = evaluate2(model, test_data, criterion, output_window, input_window)\n",
    "    \n",
    "    print('-' * 90)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f} |'.format(epoch, (time.time() - start_time),\n",
    "                                        val_loss, math.exp(val_loss)))\n",
    "    print('-' * 90)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "\n",
    "PATH = \"./weights/\"\n",
    "torch.save(model, PATH + 'model_150.pt')\n",
    "torch.save(model.state_dict(), PATH + '150_model_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    train_tmp(model, train_data,batch_size, optimizer, criterion, input_window, output_window, epoch, scheduler)\n",
    "    \n",
    "    if (epoch % 20 == 0):\n",
    "        truth, test_result, result_to_ML, val_loss = plot_and_loss2(model, test_data, criterion,input_window, output_window, scaler_test)\n",
    "    else:\n",
    "        val_loss = evaluate2(model, test_data, criterion, output_window, input_window)\n",
    "    \n",
    "    print('-' * 90)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f} |'.format(epoch, (time.time() - start_time),\n",
    "                                        val_loss, math.exp(val_loss)))\n",
    "    print('-' * 90)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "\n",
    "PATH = \"./weights/\"\n",
    "torch.save(model, PATH + '240_model.pt')\n",
    "torch.save(model.state_dict(), PATH + '240_model_state_dict.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# sklearn.set_config(array_api_dispatch=True)\n",
    "PATH = './weights/final/'\n",
    "model = torch.load(PATH + '120_model.pt') \n",
    "model.load_state_dict(torch.load(PATH + '120_model_state_dict.pt'))  \n",
    "\n",
    "DataFrame = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'label' : []}\n",
    "\n",
    "def DF_to_DataFrame(data):\n",
    "    mean = np.round(np.mean(data), 3)\n",
    "    min = np.min(data)\n",
    "    max = np.max(data)\n",
    "    std = np.std(data)\n",
    "    median = data.median()\n",
    "    sk = data.skew()\n",
    "    kurt = data.kurt()\n",
    "    a, b = np.percentile(data, q = [25,75])\n",
    "    \n",
    "    return mean, min, max, std, median, sk, kurt, a, b\n",
    "\n",
    "test_input = test_data[:, 0, :]\n",
    "test_input = test_input.unsqueeze(1)\n",
    "test_input = test_input.transpose(0, 2)\n",
    "test_input.shape\n",
    "\n",
    "test_target = test_data[:, 1, :]\n",
    "test_target = test_target.unsqueeze(1)\n",
    "test_target = test_target.transpose(0, 2)\n",
    "test_target.shape\n",
    "\n",
    "def test_batch(data, index):\n",
    "    data = data[:, :, index].unsqueeze(2)\n",
    "    return data\n",
    "\n",
    "def test_input_batch(data, index):\n",
    "    data = data[:, :, index].unsqueeze(2)\n",
    "    return data\n",
    "\n",
    "def test_target_batch(data, index):\n",
    "    data = data[:, :, index].unsqueeze(2)\n",
    "    return data\n",
    "\n",
    "def r2_score(target, output):\n",
    "    avg = target.mean()\n",
    "    avg = torch.full_like(target, avg)\n",
    "    up = mean_squared_error(target, output)\n",
    "    down = mean_squared_error(target, avg)\n",
    "    r2 = 1- (up / down)\n",
    "    return r2\n",
    "\n",
    "def test_rmse_mae_r2(target, output):\n",
    "    rmse = np.sqrt(mean_squared_error(target, output))\n",
    "    mae = mean_absolute_error(target, output)\n",
    "    r2 = r2_score(target, output)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "r2_list = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_data))):\n",
    "        input, target = test_input_batch(test_input, i), test_target_batch(test_target, i)\n",
    "        output = model(input)\n",
    "\n",
    "        output = output[-120:].detach().cpu()\n",
    "        target = target[-120:].detach().cpu()\n",
    "\n",
    "        rmse, mae, r2 = test_rmse_mae_r2(target[-120:].view(-1), output[-120:].view(-1))\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "        output = scaler_test.inverse_transform(output.reshape(-1,1)).reshape(-1)\n",
    "        output = list(output)\n",
    "        output = pd.DataFrame({'TEMP' : output})\n",
    "        A = output['TEMP']\n",
    "        mean, min, max, std, median, skew, kurt, a, b, = DF_to_DataFrame(A)\n",
    "        DataFrame['label'].append(test_label[i])\n",
    "        DataFrame['MEAN_TEMP'].append(mean)\n",
    "        DataFrame['MIN'].append(min)\n",
    "        DataFrame['MAX'].append(max)\n",
    "        DataFrame['STD'].append(std)\n",
    "        DataFrame['SKEW'].append(skew)\n",
    "        DataFrame['KURT'].append(kurt)\n",
    "        DataFrame['MEDIAN'].append(np.round(median,3))\n",
    "        DataFrame['25%'].append(np.round(a,3))\n",
    "        DataFrame['75%'].append(np.round(b,3))\n",
    "    \n",
    "print(f\"Average RMSE : {np.mean(rmse_list)}\")\n",
    "print(f\"Average MAE : {np.mean(mae_list)}\")\n",
    "print(f\"Average R2 : {np.mean(r2_list)}\")\n",
    "DF = pd.DataFrame(DataFrame)\n",
    "DF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
